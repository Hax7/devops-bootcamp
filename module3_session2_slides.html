Skip to content
Chat history

You said:
I want to build slides for module 3 session 2 I want to focus on Python for AWS and DevOps not on python basics like data types or similar things students already know that. If you can build me interactive keynote slides would be awesome if not do it as html
ChatGPT said:
Thanks! To tailor the slides effectively, could you clarify a few things:

What AWS services do you want to cover Python scripting for? (e.g., EC2, S3, Lambda, IAM, etc.)

Should the focus be on using the Boto3 library?

Are you aiming for basic automation examples or deeper infrastructure scripting (e.g., deployment, monitoring, security policies)?

Would you like embedded code exercises or quizzes for students?

How long is the session (and how many slides should I aim for)?

You said:
1.I want to focus on main AWS services like ec2, s3, security groups 
2.focus on boto3 library
3.basic automation mainly and a bit of deeper infrastructure to challenge the mind
4. yes
5. session is 3 hours long with 15 minuets break 
ChatGPT said:
Great. I‚Äôll create interactive HTML slides for Module 3, Session 2 focused on Python for AWS and DevOps, skipping basic Python concepts. The content will center on automation using the Boto3 library with core AWS services‚ÄîEC2, S3, and Security Groups. I‚Äôll include hands-on examples, quizzes, and a mix of basic and slightly advanced infrastructure automation to stretch their thinking. This will be designed to fill a 2 hour and 45 minute session with interactive engagement.

I‚Äôll let you know when the slide deck is ready for review.

Research completed in 11m ¬∑ 24 sources ¬∑ 71 searches
Python Automation with Boto3 for EC2, S3, and Security Groups

<div class="slide active"> <h1>üöÄ DevOps Bootcamp: Python Scripting for AWS with Boto3</h1> <h2>Automate AWS Tasks using Python</h2> <p>Welcome! In this session, we'll learn how to use Python's Boto3 library to automate AWS services like EC2, S3, and more, applying DevOps principles in real-world scenarios.</p> </div> <div class="slide"> <h2>Agenda</h2> <ul> <li><strong>Introduction to Boto3:</strong> Setup, authentication, and using AWS credentials.</li> <li><strong>EC2 Automation:</strong> Launching, stopping, and terminating EC2 instances with Boto3.</li> <li><strong>S3 Management:</strong> Creating buckets, uploading/downloading files, listing contents.</li> <li><strong>Security Groups:</strong> Creating groups and managing firewall rules via Boto3.</li> <li><strong>Interactive Exercises &amp; Quizzes:</strong> Hands-on mini challenges and knowledge checks throughout.</li> <li><strong>Challenge Project:</strong> Automate a basic AWS infrastructure setup using Python.</li> </ul> </div> <div class="slide"> <h2>Before We Begin</h2> <ul> <li>Assumes familiarity with core Python (no basic syntax review). We'll focus on AWS scripting.</li> <li>Requires an AWS account with API access. Have your <span class="emph">AWS access key ID</span> and <span class="emph">secret access key</span> ready (or use an IAM role).</li> <li>Recommended: Install the AWS CLI and run <code>aws configure</code> to set up credentials locally:contentReference[oaicite:0]{index=0}. This saves your credentials in <code>~/.aws/credentials</code> for Boto3 to use.</li> <li>Python 3.9+ and the <code>boto3</code> library installed on your machine.</li> </ul> </div> <div class="slide"> <h2>What is Boto3?</h2> <ul> <li><strong>Boto3</strong> is the official <span class="emph">AWS SDK for Python</span>. It allows Python developers to write software that interacts with AWS services like EC2 and S3:contentReference[oaicite:1]{index=1}.</li> <li>With Boto3, you can script and automate cloud tasks: provisioning servers, managing storage, configuring networks, and more, directly from Python.</li> <li>Use cases include <span class="emph">Infrastructure as Code</span> (replacing manual clicks with code), automation in CI/CD pipelines, scheduled jobs for maintenance (backups, cleanup), and integrating AWS operations into applications.</li> <li>Boto3 provides both a low-level <strong>Client API</strong> (direct service calls) and a higher-level <strong>Resource API</strong> (object-oriented interface). We‚Äôll use both as needed for convenience.</li> </ul> </div> <div class="slide"> <h2>Setting Up Boto3</h2> <p>First, install Boto3 in your Python environment:</p> <div class="code-block"> pip install boto3 </div> <p>Next, configure AWS credentials so Boto3 can authenticate with AWS:</p> <ul> <li><strong>Option 1:</strong> Use the AWS CLI <code>aws configure</code> command to set your <span class="emph">AWS Access Key ID</span>, <span class="emph">Secret Access Key</span>, and default region:contentReference[oaicite:2]{index=2}. This creates the credentials file under <code>~/.aws/credentials</code>.</li> <li><strong>Option 2:</strong> Manually create the credentials file with your keys, or set environment variables <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, etc. Boto3 will detect these at runtime:contentReference[oaicite:3]{index=3}:contentReference[oaicite:4]{index=4}.</li> <li><strong>Option 3:</strong> If running on AWS (e.g., an EC2 instance or Lambda), leverage an <span class="emph">IAM Role</span> for the service. Boto3 will automatically use the instance‚Äôs role credentials if no other creds are provided.</li> </ul> <div class="interactive-element">Never hard-code AWS credentials in your scripts:contentReference[oaicite:5]{index=5} ‚Äì use the above methods for safety!</div> </div> <div class="slide"> <h2>Quick Boto3 Test</h2> <p>Let's verify our setup by making a simple AWS call with Boto3. For example, list your S3 buckets:</p> <div class="code-block"> import boto3 s3 = boto3.resource('s3') for bucket in s3.buckets.all(): print(bucket.name) </div> <p>If your credentials are configured correctly, this will print the names of your S3 buckets:contentReference[oaicite:6]{index=6}. (If you have no buckets yet, it'll print nothing.) Now we're ready to automate AWS!</p> </div> <div class="slide"> <h2>Automating EC2: Amazon Elastic Compute Cloud</h2> <ul> <li><strong>Amazon EC2</strong> provides virtual servers (<em>‚Äúinstances‚Äù</em>) in the AWS cloud:contentReference[oaicite:7]{index=7}. We can use Boto3 to launch and manage these instances programmatically.</li> <li>Typical EC2 automation tasks: launching new instances for applications, scheduling start/stop for cost savings, or terminating unneeded instances automatically.</li> <li>We'll use the EC2 <span class="emph">client</span> or <span class="emph">resource</span> interfaces in Boto3. Launching an instance requires an AMI (machine image), instance type, and network settings (like VPC and security group).</li> <li>Make sure you have an appropriate <strong>AMI ID</strong> for the region (e.g., Amazon Linux 2 AMI) and a <strong>Key Pair</strong> name (for SSH access) ready before launching an instance.</li> </ul> </div> <div class="slide"> <h2>Launching an EC2 Instance (Boto3)</h2> <p>With Boto3, you can launch a new EC2 instance using the <code>run_instances</code> (client) or <code>create_instances</code> (resource) call. For example:</p> <div class="code-block"> import boto3 ec2 = boto3.resource('ec2') instances = ec2.create_instances( ImageId='ami-0abcdef1234567890', # AMI ID for your instance OS InstanceType='t2.micro', # t2.micro is free-tier eligible MinCount=1, MaxCount=1, KeyName='MyKeyPair' # Name of an existing EC2 Key Pair ) print(f"Launched instance {instances[0].id}") </div> <p>This code launches one EC2 instance using the specified AMI. Boto3 returns an instance object (or a list of instances) on success:contentReference[oaicite:8]{index=8}. Remember to use a valid AMI ID for your AWS region and a Key Pair name that exists in your account.</p> <div class="interactive-element">üïê Launching may take a minute or two. The instance will go from <span class="emph">pending</span> to <span class="emph">running</span> state. You can check progress in the AWS Console or by polling its state via Boto3.</div> </div> <div class="slide"> <h2>Stopping and Starting EC2 Instances</h2> <p>EC2 instances can be stopped when not in use (to save costs) and started again later. Use the EC2 client with the appropriate methods:</p> <div class="code-block"> ec2_client = boto3.client('ec2') # Stop an instance ec2_client.stop_instances(InstanceIds=['i-0123456789abcdef0']) # Start the same instance later ec2_client.start_instances(InstanceIds=['i-0123456789abcdef0']) </div> <p>Stopping an instance shuts it down (for EBS-backed instances, the disk state is saved). Starting brings it back online with the same data. You will not be billed for compute time while an instance is stopped, though storage (EBS) charges still apply.</p> <p><em>Note:</em> You need the instance <strong>ID</strong> (e.g., <code>i-0123456789abcdef0</code>) to stop/start. You can obtain it from the launch output or AWS Console. Ensure the instance is in a running state before stopping, and in a stopped state before starting.</p> </div> <div class="slide"> <h2>Terminating EC2 Instances</h2> <p>When an instance is no longer needed, you can <strong>terminate</strong> it (this deletes the instance permanently). Use <code>terminate_instances</code>:</p> <div class="code-block"> ec2_client = boto3.client('ec2') ec2_client.terminate_instances(InstanceIds=['i-0123456789abcdef0']) </div> <p>Terminating will shut down the instance and remove it from AWS. <strong>Note:</strong> You cannot restart or recover a terminated instance ‚Äì once terminated, it's deleted and gone:contentReference[oaicite:9]{index=9}. (You would have to launch a new instance if needed.) Be sure you really want to permanently remove an instance before terminating it.</p> <div class="interactive-element">‚ö†Ô∏è Make sure to terminate instances you no longer need to avoid ongoing charges.</div> </div> <div class="slide"> <h2>Exercise: EC2 Automation</h2> <p>Time to practice! Try the following on your own:</p> <ul> <li><strong>Launch an instance:</strong> Using Boto3, launch a new EC2 <code>t2.micro</code> instance in your default VPC. Use an appropriate AMI for your region and your Key Pair. Verify it launches successfully (e.g., use Boto3 to confirm state or check the AWS Console).</li> <li><strong>Stop and start:</strong> Write a script to stop the instance you launched. Wait a minute, then start it again. Observe the state changes (you can use the Console or Boto3 <code>describe_instances</code> to see the status).</li> <li><strong>Terminate:</strong> Finally, terminate the instance to clean up. Confirm in the AWS Console or via code that the instance is terminated (and remember, you can't restart it once terminated!).</li> </ul> <div class="interactive-element">Remember to always terminate instances you don't need to avoid charges!</div> </div> <div class="slide"> <h2>Managing S3 with Boto3</h2> <ul> <li><strong>Amazon S3</strong> (Simple Storage Service) is AWS‚Äôs scalable object storage for files, backups, logs, etc. Using Boto3, we can automate bucket and object management.</li> <li>Common tasks: creating and configuring buckets (storage containers), uploading and downloading files, listing objects, and setting permissions or lifecycle rules.</li> <li>DevOps use cases: automated backups to S3, retrieving build artifacts or logs from S3, creating buckets for deployments, cleaning up old data via scripts, and more.</li> <li>We'll focus on basic S3 operations: create a bucket, upload/download files, and list contents using Boto3's S3 client (which covers most day-to-day scripting needs).</li> </ul> </div> <div class="slide"> <h2>Creating an S3 Bucket</h2> <p>Boto3 can create new S3 buckets. For example:</p> <div class="code-block"> import boto3 s3_client = boto3.client('s3') response = s3_client.create_bucket( Bucket='my-devops-bucket-123', CreateBucketConfiguration={'LocationConstraint': 'us-west-2'} ) print(response) </div> <p>This will create a bucket named <code>my-devops-bucket-123</code> in the <code>us-west-2</code> region:contentReference[oaicite:10]{index=10}. Bucket names must be globally unique across all AWS accounts and follow naming rules (lowercase, no spaces, etc.). The response includes metadata and the bucket‚Äôs URL.</p> <div class="interactive-element">üí° Tip: Choose the AWS region closest to your users for best performance:contentReference[oaicite:11]{index=11}.</div> </div> <div class="slide"> <h2>Uploading Files to S3</h2> <p>To upload a file from your local system to an S3 bucket, use the <code>upload_file</code> function:</p> <div class="code-block"> file_path = "path/to/local/file.txt" bucket_name = "my-devops-bucket-123" object_name = "uploaded-file.txt" s3_client.upload_file(file_path, bucket_name, object_name) </div> <p>This will transfer the local file and store it in S3 as <code>uploaded-file.txt</code> in the specified bucket:contentReference[oaicite:12]{index=12}. If the file is large, Boto3 automatically uses multipart upload under the hood. After uploading, you can verify the file in the AWS Console or by listing the bucket's contents.</p> </div> <div class="slide"> <h2>Downloading Files from S3</h2> <p>Similarly, you can download an object from S3 to your local machine with <code>download_file</code>:</p> <div class="code-block"> bucket_name = "my-devops-bucket-123" object_name = "uploaded-file.txt" download_path = "path/to/save/file.txt" s3_client.download_file(bucket_name, object_name, download_path) </div> <p>This fetches the S3 object and saves it locally to <code>path/to/save/file.txt</code>:contentReference[oaicite:13]{index=13}. Ensure the destination path exists (or adjust to a valid path). Once done, open the file to confirm its contents match what was uploaded.</p> </div> <div class="slide"> <h2>Listing Buckets and Objects</h2> <p>You can list all S3 buckets in your account and the objects within a specific bucket:</p> <div class="code-block"> # List all buckets for bucket in s3_client.list_buckets()["Buckets"]: print(bucket["Name"])
List objects in a bucket
for obj in s3_client.list_objects(Bucket="my-devops-bucket-123").get("Contents", []):
print(obj["Key"]) </div> <p>The <code>list_buckets()</code> call returns all bucket names:contentReference[oaicite:14]{index=14}, and <code>list_objects()</code> returns the objects (keys) in the given bucket. We use <code>.get("Contents", [])</code> to handle the case where a bucket is empty (to avoid errors). These methods are useful for inventorying and verifying data in S3.</p> </div> <div class="slide"> <h2>Exercise: S3 Operations</h2> <p>Try these tasks to reinforce your S3 skills:</p> <ul> <li><strong>Create and upload:</strong> Create a new S3 bucket (choose a globally unique name). Then upload a sample file (e.g., a text file) to that bucket using Boto3.</li> <li><strong>List and verify:</strong> Write a script to list all your S3 buckets, and to list the objects in the new bucket to confirm your file was uploaded successfully.</li> <li><strong>Download test:</strong> Download the file from S3 to your local system and open it to verify it matches the original file.</li> <li><strong>(Optional) Cleanup:</strong> Try deleting the object and then the bucket. Remember, a bucket must be empty before it can be deleted:contentReference[oaicite:15]{index=15}.</li> </ul> <div class="interactive-element">üìù What happens if you attempt to delete a bucket that isn't empty? (Hint: AWS will prevent it with an error):contentReference[oaicite:16]{index=16}.</div> </div> <div class="slide"> <h2>Break Time ‚Äì 15 Minutes</h2> <p>Great work so far! Let's take a 15-minute break. Stand up, stretch, grab a coffee ‚òï.</p> <p>When we return: configuring security groups and a final challenge exercise. See you back in 15 minutes!</p> <div class="interactive-element">Paused ‚è∏Ô∏è ‚Äì feel free to ask questions or discuss until we resume.</div> </div> <div class="slide"> <h2>Working with Security Groups</h2> <ul> <li><strong>Security Group (SG):</strong> a virtual firewall for EC2 instances that controls inbound and outbound traffic. By default, inbound traffic is denied (except from within the same group), and outbound traffic is allowed:contentReference[oaicite:17]{index=17}.</li> <li>Security groups are <span class="emph">stateful</span>: if you allow inbound traffic on a port, the response traffic is automatically allowed outbound (and vice versa):contentReference[oaicite:18]{index=18}. This simplifies rule management (no need to create separate return traffic rules).</li> <li>You can modify SG rules at any time; changes take effect immediately for all associated instances.</li> <li>We'll use Boto3 to create a new security group and add rules to it. This automates the setup of network access (for example, opening SSH or web ports when launching an instance).</li> </ul> </div> <div class="slide"> <h2>Creating a Security Group via Boto3</h2> <p>We can create a new security group for our instances. Example:</p> <div class="code-block"> import boto3 ec2_client = boto3.client('ec2') # Determine a VPC (using the first/default VPC in the account) vpc_id = ec2_client.describe_vpcs()['Vpcs'][0]['VpcId'] response = ec2_client.create_security_group( GroupName='devops-sg', Description='Security group for DevOps demo', VpcId=vpc_id ) sg_id = response['GroupId'] print(f"Created Security Group {sg_id}") </div> <p>This creates a security group named <code>devops-sg</code> in the specified VPC:contentReference[oaicite:19]{index=19}. Initially, it has no inbound rules (meaning it will block all incoming traffic) and a default outbound ‚Äúallow all‚Äù rule. Next, we'll add some ingress rules.</p> </div> <div class="slide"> <h2>Adding Ingress Rules (Allow Traffic)</h2> <p>Now let's open some inbound ports (e.g., SSH on 22 and HTTP on 80) on our new security group:</p> <div class="code-block"> ec2_client.authorize_security_group_ingress( GroupId=sg_id, IpPermissions=[ { 'IpProtocol': 'tcp', 'FromPort': 22, 'ToPort': 22, 'IpRanges': [{'CidrIp': '0.0.0.0/0'}] }, { 'IpProtocol': 'tcp', 'FromPort': 80, 'ToPort': 80, 'IpRanges': [{'CidrIp': '0.0.0.0/0'}] } ] ) print("Inbound rules added to Security Group") </div> <p>This call adds two rules allowing TCP traffic on port 22 (SSH) and port 80 (HTTP) from anywhere (0.0.0.0/0):contentReference[oaicite:20]{index=20}. In practice, you might restrict the SSH rule to your IP range for security. Changes are applied immediately to any instances using this security group.</p> <div class="interactive-element">üí° Pro Tip: A security group rule can specify another Security Group (by ID) as the source, allowing traffic only from instances in that group (useful for tiered architectures).</div> </div> <div class="slide"> <h2>Using the Security Group</h2> <ul> <li>Our new security group <code>devops-sg</code> is ready. To use it, specify its ID when launching instances. For example, include <code>SecurityGroupIds=[sg_id]</code> in your <code>run_instances</code>/<code>create_instances</code> call to attach this SG.</li> <li>You can also assign a security group to an existing instance (via AWS Console or CLI) by modifying the instance‚Äôs security groups. This typically doesn‚Äôt require a reboot ‚Äì the changes apply on the fly.</li> <li>Any instance associated with <code>devops-sg</code> will now allow inbound SSH (22) and HTTP (80) traffic (as we configured). Outbound traffic from the instance is still unrestricted by default.</li> <li>Security groups make it easy to manage access for multiple instances: update the SG rules and all attached instances are updated together.</li> </ul> <div class="interactive-element">üîí Remember: Security Groups are your first line of defense for instances ‚Äì lock them down to only the required traffic:contentReference[oaicite:21]{index=21}.</div> </div> <div class="slide"> <h2>Knowledge Check: Boto3 & AWS</h2> <div class="quiz-question"> Which of the following is <strong>NOT</strong> a recommended way to provide AWS credentials to Boto3? <div class="quiz-options"> <div class="quiz-option">Use AWS environment variables (e.g., AWS_ACCESS_KEY_ID)</div> <div class="quiz-option">Configure credentials in <code>~/.aws/credentials</code> via AWS CLI</div> <div class="quiz-option">Attach an IAM role to the EC2 instance running the code</div> <div class="quiz-option">Hard-code the AWS access keys directly in your Python script</div> </div> </div> <div class="quiz-question"> After you <strong>terminate</strong> an EC2 instance, can you start it up again later? <div class="quiz-options"> <div class="quiz-option">True ‚Äì you can restart it within 1 hour of termination</div> <div class="quiz-option">True ‚Äì but you must pay a fee to restart a terminated instance</div> <div class="quiz-option">False ‚Äì terminated instances cannot be brought back</div> <div class="quiz-option">False ‚Äì unless you contact AWS Support</div> </div> </div> <div class="quiz-question"> Which statement about Security Groups is true? <div class="quiz-options"> <div class="quiz-option">They are stateless firewalls at the subnet level</div> <div class="quiz-option">They automatically allow return traffic for inbound rules</div> <div class="quiz-option">They block all outbound traffic by default</div> <div class="quiz-option">Rules take effect only after an instance reboot</div> </div> </div> <div class="interactive-element">Answers: Hard-coding credentials (never do this); False (once terminated, an EC2 instance cannot be restarted); Security Groups automatically allow return traffic (they are stateful).</div> </div> <div class="slide"> <h3 style="color:#004085;">üí™ Challenge: Automated AWS Setup</h3> <ul style="color:#004085; line-height:1.8;"> <li>Create a new EC2 Security Group <strong>web-sg</strong> with inbound rules allowing HTTP (port 80) and SSH (port 22) from your IP or <code>0.0.0.0/0</code> (for this exercise).</li> <li>Using Boto3, launch a <code>t2.micro</code> EC2 instance in your default VPC. Use an Amazon Linux 2 AMI and attach the <code>web-sg</code> security group. Specify your Key Pair name for SSH access.</li> <li>Automatically install a web server on launch: Hint ‚Äì use the <span class="emph">user data</span> parameter in your launch call to run a startup script (e.g., a shell script to install Apache or Nginx). <em>(Optional bonus challenge)</em></li> <li>Verify the setup: once running, try to access the instance‚Äôs web server via its public IP (HTTP on port 80) and/or SSH into it on port 22 to ensure your security group rules work.</li> <li>Upload a test file (e.g., <code>index.html</code>) to a new S3 bucket. <em>(Bonus: from the EC2 instance, use AWS CLI or Boto3 to fetch this file from S3, which may require setting up IAM roles or credentials on the instance.)</em></li> <li>Clean up: Terminate the EC2 instance and delete the S3 bucket (after emptying it) when you‚Äôre done to avoid charges.</li> </ul> <div class="interactive-element">üèÜ This challenge brings together EC2, S3, and security group automation. Give it a try! Don‚Äôt hesitate to consult AWS documentation or earlier examples for help.</div> </div> <div class="slide"> <h2>Wrap-Up &amp; Next Steps</h2> <ul> <li>In this session, we learned how to use Python and Boto3 to automate AWS tasks: launching EC2 instances, managing files in S3, and configuring security groups ‚Äì all through code.</li> <li>You‚Äôve seen how scripting AWS can save time and ensure consistency ‚Äì a key DevOps principle (treating infrastructure as code). With these skills, repetitive cloud tasks become quick scripts.</li> <li><strong>Next steps:</strong> Explore Boto3 with other services (e.g., AWS Lambda, DynamoDB, CloudWatch). As your infrastructure grows, consider infrastructure-as-code tools like AWS CloudFormation or Terraform alongside Boto3 scripts for ad-hoc automation.</li> <li>Always remember to clean up resources (terminate instances, delete unused buckets) to avoid unnecessary costs. Happy automating, and keep practicing your cloud scripting skills!</li> </ul> <div class="interactive-element">üéâ Congratulations on completing the Boto3 DevOps bootcamp session. With practice, you'll be automating AWS like a pro. Happy coding!</div> </div> <!-- Sources --> <p><small>**Sources:** Boto3 and AWS official documentation, AWS SDK code examples, and AWS developer community content were referenced to ensure accurate and up-to-date information:contentReference[oaicite:22]{index=22}:contentReference[oaicite:23]{index=23}:contentReference[oaicite:24]{index=24}:contentReference[oaicite:25]{index=25}.</small></p>





Sources
You said:
I want a downloadable html file
ChatGPT said:
Would you like the downloadable HTML file to be:

A single self-contained file (no external JS/CSS)?

Styled with a specific theme or framework (e.g., reveal.js, Bootstrap, Tailwind)?

Optimized for presentation (like full-screen navigation) or more for reading offline?

Let me know your preferences so I can generate the best version for you.

You said:
optimized for presentation
ChatGPT said:
Perfect ‚Äî I‚Äôll generate a downloadable HTML file optimized for presentation (like a full-screen slide deck) for your Python + AWS (Boto3) session. It will include the interactive structure and styling using a presentation framework such as reveal.js.

I‚Äôll prepare the file and share it with you shortly.

Research cancelled
You said:
why the fuck are you trying to do a new research? you already did and gave me a not preview able html file 
ChatGPT said:

Analyzing



No file chosenNo file chosen
ChatGPT can make mistakes. Check important info.
ChatGPT is still generating a response...

<div class="slide active"> <h1>üöÄ DevOps Bootcamp: Python Scripting for AWS with Boto3</h1> <h2>Automate AWS Tasks using Python</h2> <p>Welcome! In this session, we'll learn how to use Python's Boto3 library to automate AWS services like EC2, S3, and more, applying DevOps principles in real-world scenarios.</p> </div> <div class="slide"> <h2>Agenda</h2> <ul> <li><strong>Introduction to Boto3:</strong> Setup, authentication, and using AWS credentials.</li> <li><strong>EC2 Automation:</strong> Launching, stopping, and terminating EC2 instances with Boto3.</li> <li><strong>S3 Management:</strong> Creating buckets, uploading/downloading files, listing contents.</li> <li><strong>Security Groups:</strong> Creating groups and managing firewall rules via Boto3.</li> <li><strong>Interactive Exercises &amp; Quizzes:</strong> Hands-on mini challenges and knowledge checks throughout.</li> <li><strong>Challenge Project:</strong> Automate a basic AWS infrastructure setup using Python.</li> </ul> </div> <div class="slide"> <h2>Before We Begin</h2> <ul> <li>Assumes familiarity with core Python (no basic syntax review). We'll focus on AWS scripting.</li> <li>Requires an AWS account with API access. Have your <span class="emph">AWS access key ID</span> and <span class="emph">secret access key</span> ready (or use an IAM role).</li> <li>Recommended: Install the AWS CLI and run <code>aws configure</code> to set up credentials locally:contentReference[oaicite:0]{index=0}. This saves your credentials in <code>~/.aws/credentials</code> for Boto3 to use.</li> <li>Python 3.9+ and the <code>boto3</code> library installed on your machine.</li> </ul> </div> <div class="slide"> <h2>What is Boto3?</h2> <ul> <li><strong>Boto3</strong> is the official <span class="emph">AWS SDK for Python</span>. It allows Python developers to write software that interacts with AWS services like EC2 and S3:contentReference[oaicite:1]{index=1}.</li> <li>With Boto3, you can script and automate cloud tasks: provisioning servers, managing storage, configuring networks, and more, directly from Python.</li> <li>Use cases include <span class="emph">Infrastructure as Code</span> (replacing manual clicks with code), automation in CI/CD pipelines, scheduled jobs for maintenance (backups, cleanup), and integrating AWS operations into applications.</li> <li>Boto3 provides both a low-level <strong>Client API</strong> (direct service calls) and a higher-level <strong>Resource API</strong> (object-oriented interface). We‚Äôll use both as needed for convenience.</li> </ul> </div> <div class="slide"> <h2>Setting Up Boto3</h2> <p>First, install Boto3 in your Python environment:</p> <div class="code-block"> pip install boto3 </div> <p>Next, configure AWS credentials so Boto3 can authenticate with AWS:</p> <ul> <li><strong>Option 1:</strong> Use the AWS CLI <code>aws configure</code> command to set your <span class="emph">AWS Access Key ID</span>, <span class="emph">Secret Access Key</span>, and default region:contentReference[oaicite:2]{index=2}. This creates the credentials file under <code>~/.aws/credentials</code>.</li> <li><strong>Option 2:</strong> Manually create the credentials file with your keys, or set environment variables <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, etc. Boto3 will detect these at runtime:contentReference[oaicite:3]{index=3}:contentReference[oaicite:4]{index=4}.</li> <li><strong>Option 3:</strong> If running on AWS (e.g., an EC2 instance or Lambda), leverage an <span class="emph">IAM Role</span> for the service. Boto3 will automatically use the instance‚Äôs role credentials if no other creds are provided.</li> </ul> <div class="interactive-element">Never hard-code AWS credentials in your scripts:contentReference[oaicite:5]{index=5} ‚Äì use the above methods for safety!</div> </div> <div class="slide"> <h2>Quick Boto3 Test</h2> <p>Let's verify our setup by making a simple AWS call with Boto3. For example, list your S3 buckets:</p> <div class="code-block"> import boto3 s3 = boto3.resource('s3') for bucket in s3.buckets.all(): print(bucket.name) </div> <p>If your credentials are configured correctly, this will print the names of your S3 buckets:contentReference[oaicite:6]{index=6}. (If you have no buckets yet, it'll print nothing.) Now we're ready to automate AWS!</p> </div> <div class="slide"> <h2>Automating EC2: Amazon Elastic Compute Cloud</h2> <ul> <li><strong>Amazon EC2</strong> provides virtual servers (<em>‚Äúinstances‚Äù</em>) in the AWS cloud:contentReference[oaicite:7]{index=7}. We can use Boto3 to launch and manage these instances programmatically.</li> <li>Typical EC2 automation tasks: launching new instances for applications, scheduling start/stop for cost savings, or terminating unneeded instances automatically.</li> <li>We'll use the EC2 <span class="emph">client</span> or <span class="emph">resource</span> interfaces in Boto3. Launching an instance requires an AMI (machine image), instance type, and network settings (like VPC and security group).</li> <li>Make sure you have an appropriate <strong>AMI ID</strong> for the region (e.g., Amazon Linux 2 AMI) and a <strong>Key Pair</strong> name (for SSH access) ready before launching an instance.</li> </ul> </div> <div class="slide"> <h2>Launching an EC2 Instance (Boto3)</h2> <p>With Boto3, you can launch a new EC2 instance using the <code>run_instances</code> (client) or <code>create_instances</code> (resource) call. For example:</p> <div class="code-block"> import boto3 ec2 = boto3.resource('ec2') instances = ec2.create_instances( ImageId='ami-0abcdef1234567890', # AMI ID for your instance OS InstanceType='t2.micro', # t2.micro is free-tier eligible MinCount=1, MaxCount=1, KeyName='MyKeyPair' # Name of an existing EC2 Key Pair ) print(f"Launched instance {instances[0].id}") </div> <p>This code launches one EC2 instance using the specified AMI. Boto3 returns an instance object (or a list of instances) on success:contentReference[oaicite:8]{index=8}. Remember to use a valid AMI ID for your AWS region and a Key Pair name that exists in your account.</p> <div class="interactive-element">üïê Launching may take a minute or two. The instance will go from <span class="emph">pending</span> to <span class="emph">running</span> state. You can check progress in the AWS Console or by polling its state via Boto3.</div> </div> <div class="slide"> <h2>Stopping and Starting EC2 Instances</h2> <p>EC2 instances can be stopped when not in use (to save costs) and started again later. Use the EC2 client with the appropriate methods:</p> <div class="code-block"> ec2_client = boto3.client('ec2') # Stop an instance ec2_client.stop_instances(InstanceIds=['i-0123456789abcdef0']) # Start the same instance later ec2_client.start_instances(InstanceIds=['i-0123456789abcdef0']) </div> <p>Stopping an instance shuts it down (for EBS-backed instances, the disk state is saved). Starting brings it back online with the same data. You will not be billed for compute time while an instance is stopped, though storage (EBS) charges still apply.</p> <p><em>Note:</em> You need the instance <strong>ID</strong> (e.g., <code>i-0123456789abcdef0</code>) to stop/start. You can obtain it from the launch output or AWS Console. Ensure the instance is in a running state before stopping, and in a stopped state before starting.</p> </div> <div class="slide"> <h2>Terminating EC2 Instances</h2> <p>When an instance is no longer needed, you can <strong>terminate</strong> it (this deletes the instance permanently). Use <code>terminate_instances</code>:</p> <div class="code-block"> ec2_client = boto3.client('ec2') ec2_client.terminate_instances(InstanceIds=['i-0123456789abcdef0']) </div> <p>Terminating will shut down the instance and remove it from AWS. <strong>Note:</strong> You cannot restart or recover a terminated instance ‚Äì once terminated, it's deleted and gone:contentReference[oaicite:9]{index=9}. (You would have to launch a new instance if needed.) Be sure you really want to permanently remove an instance before terminating it.</p> <div class="interactive-element">‚ö†Ô∏è Make sure to terminate instances you no longer need to avoid ongoing charges.</div> </div> <div class="slide"> <h2>Exercise: EC2 Automation</h2> <p>Time to practice! Try the following on your own:</p> <ul> <li><strong>Launch an instance:</strong> Using Boto3, launch a new EC2 <code>t2.micro</code> instance in your default VPC. Use an appropriate AMI for your region and your Key Pair. Verify it launches successfully (e.g., use Boto3 to confirm state or check the AWS Console).</li> <li><strong>Stop and start:</strong> Write a script to stop the instance you launched. Wait a minute, then start it again. Observe the state changes (you can use the Console or Boto3 <code>describe_instances</code> to see the status).</li> <li><strong>Terminate:</strong> Finally, terminate the instance to clean up. Confirm in the AWS Console or via code that the instance is terminated (and remember, you can't restart it once terminated!).</li> </ul> <div class="interactive-element">Remember to always terminate instances you don't need to avoid charges!</div> </div> <div class="slide"> <h2>Managing S3 with Boto3</h2> <ul> <li><strong>Amazon S3</strong> (Simple Storage Service) is AWS‚Äôs scalable object storage for files, backups, logs, etc. Using Boto3, we can automate bucket and object management.</li> <li>Common tasks: creating and configuring buckets (storage containers), uploading and downloading files, listing objects, and setting permissions or lifecycle rules.</li> <li>DevOps use cases: automated backups to S3, retrieving build artifacts or logs from S3, creating buckets for deployments, cleaning up old data via scripts, and more.</li> <li>We'll focus on basic S3 operations: create a bucket, upload/download files, and list contents using Boto3's S3 client (which covers most day-to-day scripting needs).</li> </ul> </div> <div class="slide"> <h2>Creating an S3 Bucket</h2> <p>Boto3 can create new S3 buckets. For example:</p> <div class="code-block"> import boto3 s3_client = boto3.client('s3') response = s3_client.create_bucket( Bucket='my-devops-bucket-123', CreateBucketConfiguration={'LocationConstraint': 'us-west-2'} ) print(response) </div> <p>This will create a bucket named <code>my-devops-bucket-123</code> in the <code>us-west-2</code> region:contentReference[oaicite:10]{index=10}. Bucket names must be globally unique across all AWS accounts and follow naming rules (lowercase, no spaces, etc.). The response includes metadata and the bucket‚Äôs URL.</p> <div class="interactive-element">üí° Tip: Choose the AWS region closest to your users for best performance:contentReference[oaicite:11]{index=11}.</div> </div> <div class="slide"> <h2>Uploading Files to S3</h2> <p>To upload a file from your local system to an S3 bucket, use the <code>upload_file</code> function:</p> <div class="code-block"> file_path = "path/to/local/file.txt" bucket_name = "my-devops-bucket-123" object_name = "uploaded-file.txt" s3_client.upload_file(file_path, bucket_name, object_name) </div> <p>This will transfer the local file and store it in S3 as <code>uploaded-file.txt</code> in the specified bucket:contentReference[oaicite:12]{index=12}. If the file is large, Boto3 automatically uses multipart upload under the hood. After uploading, you can verify the file in the AWS Console or by listing the bucket's contents.</p> </div> <div class="slide"> <h2>Downloading Files from S3</h2> <p>Similarly, you can download an object from S3 to your local machine with <code>download_file</code>:</p> <div class="code-block"> bucket_name = "my-devops-bucket-123" object_name = "uploaded-file.txt" download_path = "path/to/save/file.txt" s3_client.download_file(bucket_name, object_name, download_path) </div> <p>This fetches the S3 object and saves it locally to <code>path/to/save/file.txt</code>:contentReference[oaicite:13]{index=13}. Ensure the destination path exists (or adjust to a valid path). Once done, open the file to confirm its contents match what was uploaded.</p> </div> <div class="slide"> <h2>Listing Buckets and Objects</h2> <p>You can list all S3 buckets in your account and the objects within a specific bucket:</p> <div class="code-block"> # List all buckets for bucket in s3_client.list_buckets()["Buckets"]: print(bucket["Name"])
List objects in a bucket
for obj in s3_client.list_objects(Bucket="my-devops-bucket-123").get("Contents", []):
print(obj["Key"]) </div> <p>The <code>list_buckets()</code> call returns all bucket names:contentReference[oaicite:14]{index=14}, and <code>list_objects()</code> returns the objects (keys) in the given bucket. We use <code>.get("Contents", [])</code> to handle the case where a bucket is empty (to avoid errors). These methods are useful for inventorying and verifying data in S3.</p> </div> <div class="slide"> <h2>Exercise: S3 Operations</h2> <p>Try these tasks to reinforce your S3 skills:</p> <ul> <li><strong>Create and upload:</strong> Create a new S3 bucket (choose a globally unique name). Then upload a sample file (e.g., a text file) to that bucket using Boto3.</li> <li><strong>List and verify:</strong> Write a script to list all your S3 buckets, and to list the objects in the new bucket to confirm your file was uploaded successfully.</li> <li><strong>Download test:</strong> Download the file from S3 to your local system and open it to verify it matches the original file.</li> <li><strong>(Optional) Cleanup:</strong> Try deleting the object and then the bucket. Remember, a bucket must be empty before it can be deleted:contentReference[oaicite:15]{index=15}.</li> </ul> <div class="interactive-element">üìù What happens if you attempt to delete a bucket that isn't empty? (Hint: AWS will prevent it with an error):contentReference[oaicite:16]{index=16}.</div> </div> <div class="slide"> <h2>Break Time ‚Äì 15 Minutes</h2> <p>Great work so far! Let's take a 15-minute break. Stand up, stretch, grab a coffee ‚òï.</p> <p>When we return: configuring security groups and a final challenge exercise. See you back in 15 minutes!</p> <div class="interactive-element">Paused ‚è∏Ô∏è ‚Äì feel free to ask questions or discuss until we resume.</div> </div> <div class="slide"> <h2>Working with Security Groups</h2> <ul> <li><strong>Security Group (SG):</strong> a virtual firewall for EC2 instances that controls inbound and outbound traffic. By default, inbound traffic is denied (except from within the same group), and outbound traffic is allowed:contentReference[oaicite:17]{index=17}.</li> <li>Security groups are <span class="emph">stateful</span>: if you allow inbound traffic on a port, the response traffic is automatically allowed outbound (and vice versa):contentReference[oaicite:18]{index=18}. This simplifies rule management (no need to create separate return traffic rules).</li> <li>You can modify SG rules at any time; changes take effect immediately for all associated instances.</li> <li>We'll use Boto3 to create a new security group and add rules to it. This automates the setup of network access (for example, opening SSH or web ports when launching an instance).</li> </ul> </div> <div class="slide"> <h2>Creating a Security Group via Boto3</h2> <p>We can create a new security group for our instances. Example:</p> <div class="code-block"> import boto3 ec2_client = boto3.client('ec2') # Determine a VPC (using the first/default VPC in the account) vpc_id = ec2_client.describe_vpcs()['Vpcs'][0]['VpcId'] response = ec2_client.create_security_group( GroupName='devops-sg', Description='Security group for DevOps demo', VpcId=vpc_id ) sg_id = response['GroupId'] print(f"Created Security Group {sg_id}") </div> <p>This creates a security group named <code>devops-sg</code> in the specified VPC:contentReference[oaicite:19]{index=19}. Initially, it has no inbound rules (meaning it will block all incoming traffic) and a default outbound ‚Äúallow all‚Äù rule. Next, we'll add some ingress rules.</p> </div> <div class="slide"> <h2>Adding Ingress Rules (Allow Traffic)</h2> <p>Now let's open some inbound ports (e.g., SSH on 22 and HTTP on 80) on our new security group:</p> <div class="code-block"> ec2_client.authorize_security_group_ingress( GroupId=sg_id, IpPermissions=[ { 'IpProtocol': 'tcp', 'FromPort': 22, 'ToPort': 22, 'IpRanges': [{'CidrIp': '0.0.0.0/0'}] }, { 'IpProtocol': 'tcp', 'FromPort': 80, 'ToPort': 80, 'IpRanges': [{'CidrIp': '0.0.0.0/0'}] } ] ) print("Inbound rules added to Security Group") </div> <p>This call adds two rules allowing TCP traffic on port 22 (SSH) and port 80 (HTTP) from anywhere (0.0.0.0/0):contentReference[oaicite:20]{index=20}. In practice, you might restrict the SSH rule to your IP range for security. Changes are applied immediately to any instances using this security group.</p> <div class="interactive-element">üí° Pro Tip: A security group rule can specify another Security Group (by ID) as the source, allowing traffic only from instances in that group (useful for tiered architectures).</div> </div> <div class="slide"> <h2>Using the Security Group</h2> <ul> <li>Our new security group <code>devops-sg</code> is ready. To use it, specify its ID when launching instances. For example, include <code>SecurityGroupIds=[sg_id]</code> in your <code>run_instances</code>/<code>create_instances</code> call to attach this SG.</li> <li>You can also assign a security group to an existing instance (via AWS Console or CLI) by modifying the instance‚Äôs security groups. This typically doesn‚Äôt require a reboot ‚Äì the changes apply on the fly.</li> <li>Any instance associated with <code>devops-sg</code> will now allow inbound SSH (22) and HTTP (80) traffic (as we configured). Outbound traffic from the instance is still unrestricted by default.</li> <li>Security groups make it easy to manage access for multiple instances: update the SG rules and all attached instances are updated together.</li> </ul> <div class="interactive-element">üîí Remember: Security Groups are your first line of defense for instances ‚Äì lock them down to only the required traffic:contentReference[oaicite:21]{index=21}.</div> </div> <div class="slide"> <h2>Knowledge Check: Boto3 & AWS</h2> <div class="quiz-question"> Which of the following is <strong>NOT</strong> a recommended way to provide AWS credentials to Boto3? <div class="quiz-options"> <div class="quiz-option">Use AWS environment variables (e.g., AWS_ACCESS_KEY_ID)</div> <div class="quiz-option">Configure credentials in <code>~/.aws/credentials</code> via AWS CLI</div> <div class="quiz-option">Attach an IAM role to the EC2 instance running the code</div> <div class="quiz-option">Hard-code the AWS access keys directly in your Python script</div> </div> </div> <div class="quiz-question"> After you <strong>terminate</strong> an EC2 instance, can you start it up again later? <div class="quiz-options"> <div class="quiz-option">True ‚Äì you can restart it within 1 hour of termination</div> <div class="quiz-option">True ‚Äì but you must pay a fee to restart a terminated instance</div> <div class="quiz-option">False ‚Äì terminated instances cannot be brought back</div> <div class="quiz-option">False ‚Äì unless you contact AWS Support</div> </div> </div> <div class="quiz-question"> Which statement about Security Groups is true? <div class="quiz-options"> <div class="quiz-option">They are stateless firewalls at the subnet level</div> <div class="quiz-option">They automatically allow return traffic for inbound rules</div> <div class="quiz-option">They block all outbound traffic by default</div> <div class="quiz-option">Rules take effect only after an instance reboot</div> </div> </div> <div class="interactive-element">Answers: Hard-coding credentials (never do this); False (once terminated, an EC2 instance cannot be restarted); Security Groups automatically allow return traffic (they are stateful).</div> </div> <div class="slide"> <h3 style="color:#004085;">üí™ Challenge: Automated AWS Setup</h3> <ul style="color:#004085; line-height:1.8;"> <li>Create a new EC2 Security Group <strong>web-sg</strong> with inbound rules allowing HTTP (port 80) and SSH (port 22) from your IP or <code>0.0.0.0/0</code> (for this exercise).</li> <li>Using Boto3, launch a <code>t2.micro</code> EC2 instance in your default VPC. Use an Amazon Linux 2 AMI and attach the <code>web-sg</code> security group. Specify your Key Pair name for SSH access.</li> <li>Automatically install a web server on launch: Hint ‚Äì use the <span class="emph">user data</span> parameter in your launch call to run a startup script (e.g., a shell script to install Apache or Nginx). <em>(Optional bonus challenge)</em></li> <li>Verify the setup: once running, try to access the instance‚Äôs web server via its public IP (HTTP on port 80) and/or SSH into it on port 22 to ensure your security group rules work.</li> <li>Upload a test file (e.g., <code>index.html</code>) to a new S3 bucket. <em>(Bonus: from the EC2 instance, use AWS CLI or Boto3 to fetch this file from S3, which may require setting up IAM roles or credentials on the instance.)</em></li> <li>Clean up: Terminate the EC2 instance and delete the S3 bucket (after emptying it) when you‚Äôre done to avoid charges.</li> </ul> <div class="interactive-element">üèÜ This challenge brings together EC2, S3, and security group automation. Give it a try! Don‚Äôt hesitate to consult AWS documentation or earlier examples for help.</div> </div> <div class="slide"> <h2>Wrap-Up &amp; Next Steps</h2> <ul> <li>In this session, we learned how to use Python and Boto3 to automate AWS tasks: launching EC2 instances, managing files in S3, and configuring security groups ‚Äì all through code.</li> <li>You‚Äôve seen how scripting AWS can save time and ensure consistency ‚Äì a key DevOps principle (treating infrastructure as code). With these skills, repetitive cloud tasks become quick scripts.</li> <li><strong>Next steps:</strong> Explore Boto3 with other services (e.g., AWS Lambda, DynamoDB, CloudWatch). As your infrastructure grows, consider infrastructure-as-code tools like AWS CloudFormation or Terraform alongside Boto3 scripts for ad-hoc automation.</li> <li>Always remember to clean up resources (terminate instances, delete unused buckets) to avoid unnecessary costs. Happy automating, and keep practicing your cloud scripting skills!</li> </ul> <div class="interactive-element">üéâ Congratulations on completing the Boto3 DevOps bootcamp session. With practice, you'll be automating AWS like a pro. Happy coding!</div> </div> <!-- Sources --> <p><small>**Sources:** Boto3 and AWS official documentation, AWS SDK code examples, and AWS developer community content were referenced to ensure accurate and up-to-date information:contentReference[oaicite:22]{index=22}:contentReference[oaicite:23]{index=23}:contentReference[oaicite:24]{index=24}:contentReference[oaicite:25]{index=25}.</small></p>
Citations
Quickstart - Boto3 1.40.25 documentation

https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html

Boto3 -Basics and S3 samples - DEV Community

https://dev.to/aws-builders/aws-boto3-sdk-10n3
Credentials - Boto3 1.40.25 documentation

https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html
Credentials - Boto3 1.40.25 documentation

https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html
Quickstart - Boto3 1.40.25 documentation

https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html

Boto3 - Managing EC2 Instances - DEV Community

https://dev.to/aws-builders/boto3-managing-ec2-instances-4n9e
create_instances - Boto3 1.40.25 documentation

https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2/service-resource/create_instances.html
Common AWS Solutions Architect Interview Questions ‚Äì IT Exams Training ‚Äì TestKing

https://www.test-king.com/blog/common-aws-solutions-architect-interview-questions/

Boto3 -Basics and S3 samples - DEV Community

https://dev.to/aws-builders/aws-boto3-sdk-10n3
module2-part3-slides.html

file://file-YSPo8cc25sDVNTX4E4u48p

Boto3 -Basics and S3 samples - DEV Community

https://dev.to/aws-builders/aws-boto3-sdk-10n3

Boto3 -Basics and S3 samples - DEV Community

https://dev.to/aws-builders/aws-boto3-sdk-10n3

Boto3 -Basics and S3 samples - DEV Community

https://dev.to/aws-builders/aws-boto3-sdk-10n3

Deleting a general purpose bucket - Amazon Simple Storage Service

https://docs.aws.amazon.com/AmazonS3/latest/userguide/delete-bucket.html

Default security groups for your VPCs - Amazon Virtual Private Cloud

https://docs.aws.amazon.com/vpc/latest/userguide/default-security-group.html

Amazon EC2 security group connection tracking - Amazon Elastic Compute Cloud

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-connection-tracking.html
Working with security groups in Amazon EC2 - Boto3 1.40.25 documentation

https://boto3.amazonaws.com/v1/documentation/api/latest/guide/ec2-example-security-group.html
Working with security groups in Amazon EC2 - Boto3 1.40.25 documentation

https://boto3.amazonaws.com/v1/documentation/api/latest/guide/ec2-example-security-group.html
module2-part3-slides.html

file://file-YSPo8cc25sDVNTX4E4u48p
All Sources
boto3.amazonaws

dev
test-king
module2-...ides.html

docs.aws.amazon
